{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f38025-c211-495d-9b5e-87134834f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from research.data.natural_scenes import NaturalScenesDataset\n",
    "from research.metrics.metrics import compute_ncsnr_fast, compute_nc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('D:\\\\Datasets\\\\NSD\\\\')\n",
    "\n",
    "derivatives_path = dataset_path / 'derivatives'\n",
    "betas_path = dataset_path / 'nsddata_betas' / 'ppdata'\n",
    "ppdata_path = dataset_path / 'nsddata' / 'ppdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save original noise ceilings generated by NSD group\n",
    "\n",
    "betas_name = 'betas_fithrf_GLMdenoise_RR'\n",
    "space = 'func1pt8'\n",
    "\n",
    "def require_dataset(group, name, data):\n",
    "    group.require_dataset(name, shape=data.shape, dtype=data.dtype)\n",
    "    group[name][:] = data\n",
    "\n",
    "with h5py.File(dataset_path / 'derivatives' / 'voxel-selection.hdf5', 'a') as f:\n",
    "    for i in range(1, 9):\n",
    "        subject_name = f'subj0{i}'\n",
    "        subject_betas_path = betas_path / subject_name / f'{space}mm' / betas_name\n",
    "\n",
    "        r2_image = nib.load(subject_betas_path / 'R2.nii.gz')\n",
    "        ncsnr_image = nib.load(subject_betas_path / 'ncsnr.nii.gz')\n",
    "        \n",
    "        r2 = np.nan_to_num(r2_image.get_fdata()).astype(float).T\n",
    "        ncsnr = np.nan_to_num(ncsnr_image.get_fdata()).astype(float).T\n",
    "        nc = ncsnr ** 2 / (ncsnr ** 2 + 1) * 100.\n",
    "        \n",
    "        grid = np.argwhere(np.ones_like(r2, dtype=bool))\n",
    "        \n",
    "        r2_sorted_indices_flat = r2.argsort(axis=None)[::-1].astype(int)\n",
    "        nc_sorted_indices_flat = nc.argsort(axis=None)[::-1].astype(int)\n",
    "        r2_sorted_indices = grid[r2_sorted_indices_flat].astype(int)\n",
    "        nc_sorted_indices = grid[nc_sorted_indices_flat].astype(int)\n",
    "        \n",
    "        group = f.require_group(subject_name)\n",
    "        \n",
    "        require_dataset(group, 'r2/value', r2)\n",
    "        require_dataset(group, 'r2/sorted_indices_flat', r2_sorted_indices_flat)\n",
    "        require_dataset(group, 'r2/sorted_indices', r2_sorted_indices)\n",
    "        \n",
    "        require_dataset(group, 'nc/value', nc)\n",
    "        require_dataset(group, 'nc/sorted_indices_flat', nc_sorted_indices_flat)\n",
    "        require_dataset(group, 'nc/sorted_indices', nc_sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = {f'subj0{i}': {} for i in range(1, 9)}\n",
    "\n",
    "for subject_name, subject_data in subjects.items():\n",
    "    responses_file_path = ppdata_path / subject_name / 'behav' / 'responses.tsv'\n",
    "    subject_data['responses'] = pd.read_csv(responses_file_path, sep='\\t',)\n",
    "    \n",
    "    # The last 3 sessions are currently held-out for the algonauts challenge\n",
    "    # remove them for now.\n",
    "    session_ids = subject_data['responses']['SESSION']\n",
    "    held_out_mask = session_ids > (np.max(session_ids) - 3)\n",
    "    subject_data['responses'] = subject_data['responses'][~held_out_mask]\n",
    "\n",
    "    subject_sessions_path = betas_path / subject_name / 'func1pt8mm' / 'betas_fithrf_GLMdenoise_RR'\n",
    "    num_sessions = np.max(subject_data['responses']['SESSION'])\n",
    "\n",
    "    subject_data['sessions'] = [\n",
    "        h5py.File(subject_sessions_path / f'betas_session{i:02}.hdf5', 'r')\n",
    "        for i in range(1, num_sessions + 1)\n",
    "    ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the betas_sessions together into a single file (this will take a while)\n",
    "\n",
    "for subject_name, subject_data in subjects.items():\n",
    "    print(subject_name)\n",
    "    path = derivatives_path / 'betas' / subject_name / 'func1pt8mm' / 'betas_fithrf_GLMdenoise_RR'\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    with h5py.File(path / 'betas_sessions.hdf5', 'a') as f:\n",
    "\n",
    "        sessions = subject_data['sessions']\n",
    "        num_sessions = len(sessions)\n",
    "        shape = sessions[0]['betas'].shape\n",
    "        T, W, H, D = shape\n",
    "        T_full = T * len(sessions)\n",
    "        \n",
    "        f.require_dataset('betas', shape=(T_full, W * H * D), dtype=np.int16, chunks=(T_full, 1))\n",
    "        for i in range(W):\n",
    "            Y = np.concatenate([\n",
    "                session['betas'][:, i]\n",
    "                for session in sessions\n",
    "            ])\n",
    "            slice_size = H * D\n",
    "            f['betas'][:, slice_size * i:slice_size * (i + 1)] = rearrange(Y, 't ... -> t (...)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e1f1b-f56c-447e-ba90-3949e2033c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the NaturalScenesDataset object\n",
    "\n",
    "nsd = NaturalScenesDataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01775854-0e7a-45ca-97f4-54c11789f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image ids of the shared 1000 images across all participants\n",
    "shared_1000_path = dataset_path / 'nsddata' / 'stimuli' / 'nsd' / 'shared1000.tsv'\n",
    "shared_1000 = pd.read_csv(shared_1000_path, sep='\\t', header=None)\n",
    "shared_1000 = set(shared_1000[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec8364-7ada-4441-b5ad-2457ca1162d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a train-test-validation split\n",
    "split_name = 'split-01'\n",
    "N_test = 1000\n",
    "N_validation = 1000\n",
    "\n",
    "seed = 0\n",
    "\n",
    "for subject_name, subject_data in nsd.subjects.items():\n",
    "    responses = subject_data['responses']\n",
    "    \n",
    "    image_ids = responses['73KID'].to_numpy()\n",
    "    unique_image_ids, unique_counts = np.unique(image_ids, return_counts=True)\n",
    "    three_repetition_ids = unique_image_ids[unique_counts == 3]\n",
    "    subject_data['three_repetition_ids'] = set(three_repetition_ids)\n",
    "    print(f'{subject_name} {image_ids.shape=}, {len(three_repetition_ids)=}')\n",
    "    \n",
    "shared_1000_three_repetitions = set.intersection(\n",
    "    shared_1000,\n",
    "    *[subject_data['three_repetition_ids']\n",
    "    for subject_data in nsd.subjects.values()]\n",
    ")\n",
    "print(f'{len(shared_1000_three_repetitions)=}')\n",
    "N_non_shared = N_test - len(shared_1000_three_repetitions)\n",
    "\n",
    "\n",
    "for subject_name, subject_data in nsd.subjects.items():\n",
    "    three_repetition_ids = subject_data['three_repetition_ids']\n",
    "    non_shared_three_repetition_ids = list(three_repetition_ids - shared_1000_three_repetitions)\n",
    "    random.Random(seed).shuffle(non_shared_three_repetition_ids)\n",
    "    \n",
    "    test_image_ids = list(shared_1000_three_repetitions) + non_shared_three_repetition_ids[:N_non_shared]\n",
    "    validation_image_ids = non_shared_three_repetition_ids[N_non_shared:(N_non_shared + N_validation)]\n",
    "    subject_data['test_image_ids'] = np.array(test_image_ids)\n",
    "    subject_data['validation_image_ids'] = np.array(test_image_ids)\n",
    "    \n",
    "    test_image_ids = set(test_image_ids)\n",
    "    validation_image_ids = set(validation_image_ids)\n",
    "    image_ids = subject_data['responses']['73KID'].to_numpy()\n",
    "    subject_data['test_response_ids'] = np.argwhere([image_id in test_image_ids for image_id in image_ids])[:, 0]\n",
    "    subject_data['validation_response_ids'] = np.argwhere([image_id in validation_image_ids for image_id in image_ids])[:, 0]\n",
    "\n",
    "(derivatives_path / 'data_splits').mkdir(exist_ok=True, parents=True)\n",
    "with h5py.File(derivatives_path / 'data_splits' / f'{split_name}.hdf5', 'w') as f:\n",
    "    for subject_name, subject_data in nsd.subjects.items():\n",
    "        subject = f.require_group(subject_name)\n",
    "        \n",
    "        three_repetition_ids = subject_data['three_repetition_ids']\n",
    "        non_shared_three_repetition_ids = list(three_repetition_ids - shared_1000_three_repetitions)\n",
    "        random.Random(seed).shuffle(non_shared_three_repetition_ids)\n",
    "\n",
    "        test_image_ids = list(shared_1000_three_repetitions) + non_shared_three_repetition_ids[:N_non_shared]\n",
    "        validation_image_ids = non_shared_three_repetition_ids[N_non_shared:(N_non_shared + N_validation)]\n",
    "        subject['test_image_ids'] = np.array(test_image_ids)\n",
    "        subject['validation_image_ids'] = np.array(test_image_ids)\n",
    "\n",
    "        test_image_ids = set(test_image_ids)\n",
    "        validation_image_ids = set(validation_image_ids)\n",
    "        image_ids = subject_data['responses']['73KID'].to_numpy()\n",
    "        subject['test_response_mask'] = np.array([image_id in test_image_ids for image_id in image_ids], dtype=bool)\n",
    "        subject['validation_response_mask'] = np.array([image_id in validation_image_ids for image_id in image_ids], dtype=bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cce7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def require_dataset(group, name, data):\n",
    "    group.require_dataset(name, shape=data.shape, dtype=data.dtype)\n",
    "    group[name][:] = data\n",
    "\n",
    "with h5py.File(nsd.dataset_path / 'derivatives/noise-ceiling.hdf5', 'a') as f:\n",
    "    for subject_id in range(8):\n",
    "        subject_name = f'subj0{subject_id + 1}'\n",
    "        print(subject_name)\n",
    "        \n",
    "        subject = nsd.subjects[subject_name]\n",
    "        train_mask = nsd.get_split(subject_name, 'split-01')[0]\n",
    "\n",
    "        betas_h5 = subject['betas']\n",
    "        responses = subject['responses']\n",
    "        stimulus_ids = np.array(responses['73KID']) - 1\n",
    "        stimulus_ids = stimulus_ids[train_mask]\n",
    "\n",
    "        n = 3\n",
    "        unique_ids, unique_counts = np.unique(stimulus_ids, return_counts=True)\n",
    "        atleast_n_ids = unique_ids[unique_counts >= n]\n",
    "        repetition_ids = np.stack([\n",
    "            np.where(stimulus_ids == i)[0][:n]\n",
    "            for i in atleast_n_ids\n",
    "        ])\n",
    "\n",
    "        num_betas, num_voxels = betas_h5['betas'].shape\n",
    "        voxel_batch_size = 10000\n",
    "        indices_batches = np.array_split(np.arange(num_voxels), num_voxels // voxel_batch_size)\n",
    "        ncsnr = []\n",
    "\n",
    "        for betas_indices in indices_batches:\n",
    "            print(f'{betas_indices[-1]}/{num_voxels}, {betas_indices[-1] / num_voxels * 100:.1f}%')\n",
    "            betas = nsd.load_betas(subject_name, betas_indices=betas_indices, return_tensor_dataset=False)[0]\n",
    "            betas = betas[train_mask]\n",
    "            ncsnr.append(compute_ncsnr_fast(betas, repetition_ids))\n",
    "        ncsnr = np.concatenate(ncsnr)\n",
    "\n",
    "        nc = compute_nc(ncsnr, num_averages=1)\n",
    "\n",
    "        voxel_selection_path = 'derivatives/voxel-selection.hdf5'\n",
    "        voxel_selection_key = 'nc/value'\n",
    "\n",
    "        voxel_selection_file = h5py.File(nsd.dataset_path / voxel_selection_path, 'r')\n",
    "        key = f'{subject_name}/{voxel_selection_key}'\n",
    "        nc_original = voxel_selection_file[key][:]\n",
    "        \n",
    "        nc = nc.reshape(nc_original.shape)\n",
    "        nc[np.isnan(nc)] = 0.\n",
    "        grid = np.argwhere(np.ones_like(nc, dtype=bool))\n",
    "        nc_sorted_indices_flat = nc.argsort(axis=None)[::-1].astype(int)\n",
    "        nc_sorted_indices = grid[nc_sorted_indices_flat].astype(int)\n",
    "        \n",
    "        require_dataset(f, f'{subject_name}/split-01/value', nc)\n",
    "        require_dataset(f, f'{subject_name}/split-01/sorted_indices_flat', nc_sorted_indices_flat)\n",
    "        require_dataset(f, f'{subject_name}/split-01/sorted_indices', nc_sorted_indices)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f93265",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "nsd_path = Path('D:\\\\Datasets\\\\NSD')\n",
    "stimuli_path = nsd_path / 'nsddata_stimuli' / 'stimuli' / 'nsd' / 'nsd_stimuli.hdf5'\n",
    "stimulus_images = h5py.File(stimuli_path, 'r')['imgBrick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a clip model\n",
    "import clip\n",
    "\n",
    "print(clip.available_models())\n",
    "model_name = 'ViT-B/32'\n",
    "full_model, preprocess = clip.load(model_name, device=device)\n",
    "model = full_model.visual\n",
    "\n",
    "save_modules = {\n",
    "    '': 'embedding'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ece85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "#from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "from typing import Sequence, Dict\n",
    "\n",
    "out_path = dataset_path / 'derivatives' / 'stimulus_embeddings'\n",
    "out_path.mkdir(exist_ok=True, parents=True)\n",
    "modules = dict(model.named_modules())\n",
    "\n",
    "with h5py.File(out_path / f\"{model_name.replace('/', '=').replace('@', '-')}.hdf5\", \"a\") as f:\n",
    "    N = stimulus_images.shape[0]\n",
    "    for stimulus_id in range(N):\n",
    "        image_data = stimulus_images[stimulus_id]\n",
    "\n",
    "        image = Image.fromarray(image_data)\n",
    "        x = preprocess(image).unsqueeze(0).to(device) #.to(torch.float16)\n",
    "\n",
    "        features = {}\n",
    "        def forward_hook(module_name, module, x_in, x_out):\n",
    "            if x_out.shape[0] == 1:\n",
    "                x_out = x_out[0]\n",
    "            features[module_name] = x_out.clone().cpu().float().numpy()\n",
    "        hook_handles = []\n",
    "        if isinstance(save_modules, Sequence):\n",
    "            for module_name in save_modules:\n",
    "                module = modules[module_name]\n",
    "                hook_handle = module.register_forward_hook(partial(forward_hook, module_name))\n",
    "                hook_handles.append(hook_handle)\n",
    "        elif isinstance(save_modules, Dict):\n",
    "            for module_name, feature_name in save_modules.items():\n",
    "                module = modules[module_name]\n",
    "                hook_handle = module.register_forward_hook(partial(forward_hook, feature_name))\n",
    "                hook_handles.append(hook_handle)\n",
    "        with torch.no_grad():\n",
    "            model(x)\n",
    "        for hook_handle in hook_handles:\n",
    "            hook_handle.remove()\n",
    "        for feature_name, feature in features.items():\n",
    "            f.require_dataset(feature_name, (N, *feature.shape), feature.dtype)\n",
    "            f[feature_name][stimulus_id] = feature\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
