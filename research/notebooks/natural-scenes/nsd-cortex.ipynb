{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9dfa1-6262-40d2-b181-5554fc4d47ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cortex\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb, to_rgb\n",
    "import os\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "from nibabel.freesurfer.io import read_annot, write_annot\n",
    "\n",
    "\n",
    "print(cortex.options.usercfg)\n",
    "print(cortex.database.default_filestore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf78a47-7524-4fbe-b8b5-854e5863daed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d76374c-6ebc-4809-a8f4-c6ee20efe187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsd_path = Path('/mnt/d/Datasets/NSD/')\n",
    "freesurfer_path = nsd_path / 'nsddata/freesurfer/'\n",
    "\n",
    "subjects = [f'subj0{i + 1}' for i in range(8)]\n",
    "\n",
    "roi_names = {\n",
    "    'prf-visualrois': ['V1', 'V2', 'V3', 'V4'],\n",
    "    'floc-bodies': ['mTL-bodies', 'FBA-1', 'FBA-2', 'EBA'],\n",
    "    'floc-faces': ['aTL-faces', 'mTL-faces', 'FFA-2', 'FFA-1', 'OFA'],\n",
    "    'floc-places': ['RSC', 'PPA', 'OPA'],\n",
    "    'floc-words': ['mTL-words', 'mfs-words', 'VWFA-2' 'VWFA-1', 'OWFA'], \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8710de3-aadc-4870-94ac-91368aa0af04",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647bbf1-6821-4361-b227-e8b6c5408f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_cmap(nlabels, type='bright', first_color_black=True, last_color_black=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Creates a random colormap to be used together with matplotlib. Useful for segmentation tasks\n",
    "    :param nlabels: Number of labels (size of colormap)\n",
    "    :param type: 'bright' for strong colors, 'soft' for pastel colors\n",
    "    :param first_color_black: Option to use first color as black, True or False\n",
    "    :param last_color_black: Option to use last color as black, True or False\n",
    "    :param verbose: Prints the number of labels and shows the colormap. True or False\n",
    "    :return: colormap for matplotlib\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    import colorsys\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    if type not in ('bright', 'soft'):\n",
    "        print ('Please choose \"bright\" or \"soft\" for type')\n",
    "        return\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of labels: ' + str(nlabels))\n",
    "\n",
    "    # Generate color map for bright colors, based on hsv\n",
    "    if type == 'bright':\n",
    "        randHSVcolors = [(np.random.uniform(low=0.0, high=1),\n",
    "                          np.random.uniform(low=0.2, high=1),\n",
    "                          np.random.uniform(low=0.9, high=1)) for i in range(nlabels)]\n",
    "\n",
    "        # Convert HSV list to RGB\n",
    "        randRGBcolors = []\n",
    "        for HSVcolor in randHSVcolors:\n",
    "            randRGBcolors.append(colorsys.hsv_to_rgb(HSVcolor[0], HSVcolor[1], HSVcolor[2]))\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Generate soft pastel colors, by limiting the RGB spectrum\n",
    "    if type == 'soft':\n",
    "        low = 0.6\n",
    "        high = 0.95\n",
    "        randRGBcolors = [(np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high)) for i in range(nlabels)]\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Display colorbar\n",
    "    if verbose:\n",
    "        from matplotlib import colors, colorbar\n",
    "        from matplotlib import pyplot as plt\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 0.5))\n",
    "\n",
    "        bounds = np.linspace(0, nlabels, nlabels + 1)\n",
    "        norm = colors.BoundaryNorm(bounds, nlabels)\n",
    "\n",
    "        cb = colorbar.ColorbarBase(ax, cmap=random_colormap, norm=norm, spacing='proportional', ticks=None,\n",
    "                                   boundaries=bounds, format='%1i', orientation=u'horizontal')\n",
    "\n",
    "    return random_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a443e16-ba20-4184-a08c-64f003db3495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_flat(fs_subject, patch, hemis=['lh', 'rh'], cx_subject=None,\n",
    "                flat_type='freesurfer', auto_overwrite=False,\n",
    "                freesurfer_subject_dir=None, clean=True):\n",
    "    \"\"\"Imports a flat brain from freesurfer\n",
    "\n",
    "    NOTE: This will delete the overlays.svg file for this subject, since THE\n",
    "    FLATMAPS WILL CHANGE, as well as all cached information (e.g. old flatmap \n",
    "    boundaries, roi svg intermediate renders, etc). \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fs_subject : str\n",
    "        Freesurfer subject name\n",
    "    patch : str\n",
    "        Name of flat.patch.3d file; e.g., \"flattenv01\"\n",
    "    hemis : list\n",
    "        List of hemispheres to import. Defaults to both hemispheres.\n",
    "    cx_subject : str\n",
    "        Pycortex subject name\n",
    "    freesurfer_subject_dir : str\n",
    "        directory for freesurfer subjects. None defaults to evironment variable\n",
    "        $SUBJECTS_DIR\n",
    "    clean : bool\n",
    "        If True, the flat surface is cleaned to remove the disconnected polys.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    if not auto_overwrite:\n",
    "        proceed = input(('Warning: This is intended to over-write .gii files storing\\n'\n",
    "                         'flatmap vertex locations for this subject, and will result\\n'\n",
    "                         'in deletion of the overlays.svg file and all cached info\\n'\n",
    "                         'for this subject (because flatmaps will fundamentally change).\\n'\n",
    "                         'Proceed? [y]/n: '))\n",
    "        if proceed.lower() not in ['y', 'yes', '']:\n",
    "            print(\">>> Elected to quit rather than delete & overwrite files.\")\n",
    "            return\n",
    "\n",
    "    if cx_subject is None:\n",
    "        cx_subject = fs_subject\n",
    "    surfs = os.path.join(cortex.database.default_filestore, cx_subject, \"surfaces\", \"flat_{hemi}.gii\")\n",
    "\n",
    "    for hemi in hemis:\n",
    "        if flat_type == 'freesurfer':\n",
    "            pts, polys, _ = cortex.freesurfer.get_surf(fs_subject, hemi, \"patch\", patch+\".flat\", freesurfer_subject_dir=freesurfer_subject_dir)\n",
    "            flat = pts\n",
    "            # Reorder axes: X, Y, Z instead of Y, X, Z\n",
    "            #flat = pts[:, [1, 0, 2]]\n",
    "            # Flip Y axis upside down\n",
    "            #flat[:, 1] = -flat[:, 1]\n",
    "        elif flat_type == 'slim':\n",
    "            flat_file = cortex.freesurfer.get_paths(fs_subject, hemi, type='slim',\n",
    "                                  freesurfer_subject_dir=freesurfer_subject_dir)\n",
    "            flat_file = flat_file.format(name=patch + \".flat\")\n",
    "            flat, polys = formats.read_obj(flat_file)\n",
    "\n",
    "        if clean:\n",
    "            polys = cortex.freesurfer._remove_disconnected_polys(polys)\n",
    "            flat = cortex.freesurfer._move_disconnect_points_to_zero(flat, polys)\n",
    "\n",
    "        fname = surfs.format(hemi=hemi)\n",
    "        print(\"saving to %s\"%fname)\n",
    "        cortex.formats.write_gii(fname, pts=flat, polys=polys)\n",
    "\n",
    "    # clear the cache, per #81\n",
    "    cortex.database.db.clear_cache(cx_subject)\n",
    "    # Remove overlays.svg file (FLATMAPS HAVE CHANGED)\n",
    "    overlays_file = cortex.database.db.get_paths(cx_subject)['overlays']\n",
    "    if os.path.exists(overlays_file):\n",
    "        os.unlink(overlays_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b4cbc-ec31-4e42-bd68-1412eee49d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cortex\n",
    "for subject_id in range(8):\n",
    "    cortex.freesurfer.import_subj(f'subj0{subject_id + 1}', freesurfer_subject_dir=freesurfer_path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe0d28-5f3b-4864-8050-cb210cf22bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cortex.freesurfer.import_subj(f'fsaverage', freesurfer_subject_dir=freesurfer_path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc9fb58-6099-4e32-a66c-1285c0f103be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for subject_id in range(8):\n",
    "    import_flat(f'subj0{subject_id + 1}', 'full', freesurfer_subject_dir=freesurfer_path, auto_overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6529674-4e5f-40a9-884c-102caf6369d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_name = 'modified_dbscan5'\n",
    "reruns_mode = 'multiple'\n",
    "tag = 'linear_decoding__group-22_reruns-2'\n",
    "results_path = nsd_path / f'derivatives/figures/concept_maps_voxel_v5/{tag}'\n",
    "\n",
    "W_concat = np.load(results_path / f'{tag}__W.npy')\n",
    "W = []\n",
    "for cluster_id in np.unique(cluster)[1:]:\n",
    "    W.append(np.mean(W_concat[cluster == cluster_id], axis=0))\n",
    "W = np.stack(W)\n",
    "W = W / np.linalg.norm(W, axis=-1, keepdims=True)\n",
    "W.shape\n",
    "\n",
    "masks = [np.load(results_path / run_name / subject_name / 'mask.npy') for subject_name in subjects]\n",
    "\n",
    "component_label_names = np.arange(masks[0].shape[0])\n",
    "component_ids = np.array(component_label_names)\n",
    "#voxel_counts = np.zeros((8, component_ids.shape[0]), dtype=int))\n",
    "voxel_counts = np.stack([(mask > 0).sum(axis=1) for mask in masks])\n",
    "\n",
    "subject_ids = np.load(results_path / f'{tag}__subject_id.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d9acc-5b91-4023-ac60-badb73b600e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "num_models = 1\n",
    "min_neighbors_grid = (3,)\n",
    "eps_grid = (0.55, 0.6, 0.65, 0.5, 0.7, 0.45)\n",
    "tag = 'linear_decoding__group-22_reruns-2'\n",
    "#tag = 'linear_encoding_large'\n",
    "suffix = '_expanded'\n",
    "num_vertices = 163842\n",
    "\n",
    "overwrite_time = 0 * 60 * 60\n",
    "\n",
    "for min_neighbors in (min_neighbors_grid): #(1, 2, 3, 4):\n",
    "    for i, eps in enumerate(eps_grid):\n",
    "        gc.collect()\n",
    "        print(f'{min_neighbors=}, {i=}, {eps=}')\n",
    "        run_name = f'num_models-{num_models}/min_neighbors-{min_neighbors}/run-{i}'\n",
    "        reruns_mode = 'multiple'\n",
    "        \n",
    "        results_path = nsd_path / f'derivatives/figures/concept_maps_voxel_v5/{tag}'\n",
    "\n",
    "        masks = [np.load(results_path / run_name / subject_name / f'mask{suffix}.npy') for subject_name in subjects]\n",
    "\n",
    "        component_label_names = np.arange(masks[0].shape[0])\n",
    "        component_ids = np.array(component_label_names)\n",
    "        #voxel_counts = np.zeros((8, component_ids.shape[0]), dtype=int))\n",
    "        voxel_counts = np.stack([(mask > 0).sum(axis=1) for mask in masks])\n",
    "\n",
    "        subject_ids = np.load(results_path / f'{tag}__subject_id.npy')\n",
    "\n",
    "\n",
    "        space = 'fsavg'\n",
    "        gyri_and_sulci_list = ['STS', 'SF', 'IPS', 'poCS', '⠀', 'ORBS', 'SFS', 'IFS', 'preCS', 'CS']\n",
    "        HCP_roi_list = ['IPS1', 'MIP', 'IP1', 'IP0', 'PF', 'PSL', 'PGi', 'STV', 'TPOJ1']\n",
    "        roi_list = ['V1', 'V2', 'V3', 'V4', 'OPA', 'RSC', 'PPA', 'EBA', 'FFA', ]# +  roi_names['floc-words']\n",
    "        roi_list += gyri_and_sulci_list\n",
    "\n",
    "        subject_colors = [to_rgb(f'tab:{c}') for c in ('blue', 'orange', 'green', 'red', 'purple', 'pink', 'olive', 'brown')]\n",
    "        subject_colors = np.array(subject_colors)\n",
    "\n",
    "        mixing_behavior = 'white'\n",
    "\n",
    "        voxel_ids_all = [\n",
    "            np.load(nsd_path / f'derivatives/figures/concept_maps_voxel_v5/{tag}/voxel_ids__{space}__{subject_name}.npy') \n",
    "            for subject_name in subjects\n",
    "        ]\n",
    "\n",
    "        for component_id in component_ids:\n",
    "            mask_path = results_path / run_name\n",
    "            out_path = mask_path / f'pycortex_flatmaps/component_colors{suffix}'\n",
    "            out_path.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            if (out_path / f'component-{component_id}.png').exists():\n",
    "                creation_time = (out_path / f'component-{component_id}.png').stat().st_ctime\n",
    "                time_since_creation = time.time() - creation_time\n",
    "                print(f'{creation_time=}, {time.time()=}, {time_since_creation=}')\n",
    "                if time_since_creation < overwrite_time:\n",
    "                    print(f'skipping {component_id=}')\n",
    "                    continue\n",
    "                else:\n",
    "                    print('plotting')\n",
    "\n",
    "            data_all = []\n",
    "            for subject_id in range(8):\n",
    "                subject_name = f'subj0{subject_id + 1}'\n",
    "                subject_path = mask_path / subject_name\n",
    "\n",
    "                #lh_data = np.load(subject_path / f'mask__component-{component_id}__{space}__lh.npy')\n",
    "                #rh_data = np.load(subject_path / f'mask__component-{component_id}__{space}__rh.npy')\n",
    "\n",
    "                #data = np.concatenate([lh_data, rh_data], axis=1)\n",
    "\n",
    "                if reruns_mode == 'average':\n",
    "                    subject_data = cluster[subject_ids == subject_id]\n",
    "                    subject_data = (subject_data == component_id).astype(float)\n",
    "                elif reruns_mode == 'multiple':\n",
    "                    subject_data = (masks[subject_id][component_id] > 0).astype(float)\n",
    "                data = subject_data[voxel_ids_all[subject_id]]\n",
    "                data[voxel_ids_all[subject_id] == -1] = np.nan\n",
    "\n",
    "                data = np.nanmax(data, axis=1)\n",
    "                data_all.append(data)\n",
    "            data_all = np.stack(data_all)\n",
    "            print(data_all.shape)\n",
    "            all_nan = np.all(np.isnan(data_all), axis=0)\n",
    "            \n",
    "            data_all_ids = np.zeros((data_all.shape[1],)).astype(int)\n",
    "            for vertex_id, vertex_data in enumerate(data_all.T):\n",
    "                subject_ids = np.where(vertex_data == 1.)[0]\n",
    "                if subject_ids.shape[0] > 1:\n",
    "                    data_all_ids[vertex_id] = 9\n",
    "                elif subject_ids.shape[0] == 1:\n",
    "                    data_all_ids[vertex_id] = subject_ids[0] + 1\n",
    "            data_all_ids[all_nan] = -1\n",
    "            data_all_ids += 1\n",
    "            lh_data_all_ids, rh_data_all_ids = np.split(data_all_ids, 2)\n",
    "            \n",
    "            ctab = (subject_colors * 255)\n",
    "            ctab = np.concatenate([ctab, np.zeros(((ctab.shape[0], 1)))], axis=1)\n",
    "            ctab = np.concatenate([[[0, 0, 0, 255], [1, 1, 1, 0]], ctab, [[255, 255, 255, 0]]])\n",
    "            label_names = ['unknown', 'model_input', *subjects, 'overlap']\n",
    "            \n",
    "            write_annot(out_path / f'lh.component-{component_id}.annot', lh_data_all_ids, ctab, label_names, fill_ctab=True)\n",
    "            write_annot(out_path / f'rh.component-{component_id}.annot', rh_data_all_ids, ctab, label_names, fill_ctab=True)\n",
    "            \n",
    "            all_nan = np.all(np.isnan(data_all), axis=0)\n",
    "\n",
    "            num_overlaps = np.nansum(data_all, axis=0)\n",
    "            print(num_overlaps.shape, data_all.shape)\n",
    "            num_vertices = data_all.shape[1]\n",
    "\n",
    "            data_color = data_all.T @ subject_colors\n",
    "            data_color = np.zeros((num_vertices, 3))\n",
    "\n",
    "            for subject_id in range(8):\n",
    "                data_color[data_all[subject_id] == 1] = subject_colors[subject_id]\n",
    "\n",
    "            if mixing_behavior == 'white':\n",
    "                data_color[num_overlaps > 1] = 1\n",
    "            data_color[all_nan] = np.nan\n",
    "            #data_color[np.all(data_color == np.nan, axis=1) & (~all_nan)] = 0.\n",
    "            \n",
    "            word_rois = ['V1', 'V2', 'V3', 'V4', 'OPA', 'RSC', 'PPA', 'EBA', 'VWFA-1', 'VWFA-2', 'msf-words', 'mTL-words', 'OWFA'] #+ HCP_roi_list + gyri_and_sulci_list\n",
    "            if eps == 0.6 and component_id == 11:\n",
    "                use_rois = word_rois \n",
    "            else:\n",
    "                use_rois = roi_list\n",
    "            \n",
    "            data_color = [cortex.dataset.Vertex(data, subject_name if space == 'fssubject' else 'fsaverage', vmin=0, vmax=1) for data in data_color.T]\n",
    "            #data_color = (data_color * 255).astype(np.uint8)\n",
    "            braindata = cortex.dataset.VertexRGB(*data_color, subject_name)\n",
    "            #braindata = braindata.blend_curvature(braindata)\n",
    "            overlay_file = f'{subject_name}/overlays_version1.svg' if space == 'fssubject' else f'fsaverage/overlays_floc.svg'\n",
    "            cortex.quickflat.make_figure(braindata, with_sulci=False, with_rois=True, with_curvature=True, with_colorbar=False, #colorbar_location=(0.01, 0.05, 0.2, 0.05),\n",
    "                                         overlay_file=Path(cortex.database.default_filestore) / overlay_file,\n",
    "                                         roi_list=roi_list)\n",
    "\n",
    "\n",
    "            handles = []\n",
    "            for i, subject_name in enumerate(subjects):\n",
    "                num_voxels = voxel_counts[i, component_id]\n",
    "                if num_voxels == 0:\n",
    "                    continue\n",
    "                handles.append(mpatches.Patch(color=subject_colors[i], label=f'{subject_name} ({num_voxels})'))\n",
    "            #for label, color in legend_data:\n",
    "            #    handles.append(mpatches.Patch(color=color, label=label))\n",
    "\n",
    "            if mixing_behavior == 'white':\n",
    "                handles.append(mpatches.Patch(color=(1, 1, 1), label=f'overlap'))\n",
    "            plt.legend(handles=handles, loc='upper center', ncols=4)\n",
    "\n",
    "            plt.savefig(out_path / f'component-{component_id}.png')\n",
    "            cortex.quickflat.make_svg(out_path / f'component-{component_id}.svg', braindata, with_curvature=True, with_labels=True,\n",
    "                                         overlay_file=Path(cortex.database.default_filestore) / overlay_file,)\n",
    "            plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
